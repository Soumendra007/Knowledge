{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca8f208",
   "metadata": {},
   "source": [
    "# Types of Cross Validation Final:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6baa63c",
   "metadata": {},
   "source": [
    "1) Holdout cross-validation:-\n",
    "\n",
    "    The holdout technique is an exhaustive cross-validation method, that randomly splits the dataset into train and test data depending on data analysis.In the case of holdout cross-validation, the dataset is randomly split into training and validation data. Generally, the split of training data is more than test data. The training data is used to induce the model and validation data is evaluates the performance of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3490f4c",
   "metadata": {},
   "source": [
    "2) K fold Cross Validation:-\n",
    "\n",
    "In k-fold cross-validation, the original dataset is equally partitioned into k subparts or folds. Out of the k-folds or groups, for each iteration, one group is selected as validation data, and the remaining (k-1) groups are selected as training data. The process is repeated for k times until each group is treated as validation and remaining as training data.\n",
    "The final accuracy of the model is computed by taking the mean accuracy of the k-models validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed4773",
   "metadata": {},
   "source": [
    "3) Leave-one-out cross-validation:-\n",
    "\n",
    "    Leave-one-out cross-validation (LOOCV) is an exhaustive cross-validation technique. For a dataset having n rows, 1st row is selected for validation, and the rest (n-1) rows are used to train the model. For the next iteration, the 2nd row is selected for validation and rest to train the model. Similarly, the process is repeated until n steps or the desired number of operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcb119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5814c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e44d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02dad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a5fcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd1ca76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.data)\n",
    "print(iris.feature_names)\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "032fa848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c03c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36409db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "..   ...  ...  ...  ...\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(iris.data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed61b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ed6665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49fdca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.22,random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3487a54a",
   "metadata": {},
   "source": [
    "# Using MultinomialNB classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daad4eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb=MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "predmnb=mnb.predict(x_test)\n",
    "print(accuracy_score(y_test,predmnb))\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1fc53",
   "metadata": {},
   "source": [
    "# Using SVC with different karnel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c3fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernellist=[\"rbf\",\"poly\",\"linear\"]  #poly is default for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b556595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for  rbf in SVC is: 0.9393939393939394\n",
      "Confusion matrix for  rbf in SVC is: [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  7]]\n",
      "Classification report for  rbf in SVC is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.93      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "Accuracy score for  poly in SVC is: 1.0\n",
      "Confusion matrix for  poly in SVC is: [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "Classification report for  poly in SVC is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n",
      "Accuracy score for  linear in SVC is: 1.0\n",
      "Confusion matrix for  linear in SVC is: [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "Classification report for  linear in SVC is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in kernellist:\n",
    "    svc=SVC(kernel=i)\n",
    "    svc.fit(x_train,y_train)\n",
    "    predsvc=svc.predict(x_test)\n",
    "    print(\"Accuracy score for \",i,\"in SVC is:\",accuracy_score(y_test,predsvc))\n",
    "    print(\"Confusion matrix for \",i,\"in SVC is:\",confusion_matrix(y_test,predsvc))\n",
    "    print(\"Classification report for \",i,\"in SVC is:\",classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2bca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38870718",
   "metadata": {},
   "source": [
    "# Using DecisionTreeClassifier with different criterion values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7646ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterionlist=[\"gini\",\"entropy\"] #gini is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63d5b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for  gini in dtc is: 0.9393939393939394\n",
      "Confusion matrix for  gini in dtc is: [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  7]]\n",
      "Classification report for  gini in dtc is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.93      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n",
      "Accuracy score for  entropy in dtc is: 0.9393939393939394\n",
      "Confusion matrix for  entropy in dtc is: [[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  7]]\n",
      "Classification report for  entropy in dtc is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.93      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in criterionlist:\n",
    "    dtc=DecisionTreeClassifier(criterion=i)\n",
    "    dtc.fit(x_train,y_train)\n",
    "    preddtc=dtc.predict(x_test)\n",
    "    print(\"Accuracy score for \",i,\"in dtc is:\",accuracy_score(y_test,preddtc))\n",
    "    print(\"Confusion matrix for \",i,\"in dtc is:\",confusion_matrix(y_test,preddtc))\n",
    "    print(\"Classification report for \",i,\"in dtc is:\",classification_report(y_test,preddtc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8e654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "828b2c0f",
   "metadata": {},
   "source": [
    "# Using KNeighborsClassifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16a8327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn= KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "predknn=knn.predict(x_test)\n",
    "print(accuracy_score(y_test,predknn))\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41566134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a552d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb8e152",
   "metadata": {},
   "source": [
    "# Now I will going to use k fold cross_validation with different model I just used earlier.Lets see how can I do that:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba935053",
   "metadata": {},
   "source": [
    "# Checking cross_val_score for mnb model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46be1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.96666667 0.9        0.9        1.        ]\n",
      "0.9533333333333334\n",
      "0.04521553322083511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score=cross_val_score(mnb,x,y,cv=5)#cv=5 is default you can change it to any number so your dataset goes through that much round\n",
    "print(score)\n",
    "print(score.mean())\n",
    "print(score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc5956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47fd2a14",
   "metadata": {},
   "source": [
    "# Checking cross_val_score for svc model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f86ff1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "0.9800000000000001\n",
      "0.016329931618554516\n"
     ]
    }
   ],
   "source": [
    "scoresvc=cross_val_score(svc,x,y,cv=5)#cv=5 is default you can change it to any number so your dataset goes through that much round\n",
    "print(scoresvc)\n",
    "print(scoresvc.mean())\n",
    "print(scoresvc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e9672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f183a27",
   "metadata": {},
   "source": [
    "# Checking cross_val_score for dtc model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e147fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "0.9600000000000002\n",
      "0.03265986323710903\n"
     ]
    }
   ],
   "source": [
    "scoredtc=cross_val_score(dtc,x,y,cv=5)#cv=5 is default you can change it to any number so your dataset goes through that much round\n",
    "print(scoredtc)\n",
    "print(scoredtc.mean())\n",
    "print(scoredtc.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf9a06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97eeeb8",
   "metadata": {},
   "source": [
    "# Checking cross_val_score for knn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64111b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "0.9733333333333334\n",
      "0.02494438257849294\n"
     ]
    }
   ],
   "source": [
    "scoreknn=cross_val_score(knn,x,y,cv=5)\n",
    "print(scoreknn)\n",
    "print(scoreknn.mean())\n",
    "print(scoreknn.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365345cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1c2581c",
   "metadata": {},
   "source": [
    "# By checking all model's cross_val_score I can say svc is the best model for this iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056bd85",
   "metadata": {},
   "source": [
    "# Checking my svc model prediction by giving an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65817f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array([6.4, 3.2, 4.5 ,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d6b8711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f4ab113",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f01ca6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d31623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c61753f7",
   "metadata": {},
   "source": [
    "# Now I will create a user define function that automaticaly reshape any 4 values array into 2d data and predict the flower type with svc model.Lets see how can I do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905f7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f35ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediris(x):\n",
    "    x=x.reshape(1,-1)\n",
    "    t=svc.predict(x)\n",
    "    if t==0:\n",
    "        print(\"It is setosa \")\n",
    "    elif t==1:\n",
    "        print(\"It is versicolor \")\n",
    "    else:\n",
    "        print(\"It is virginica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b8e3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array([4.8,3.5,1.7,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c73a85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is setosa \n"
     ]
    }
   ],
   "source": [
    "prediris(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8958a67",
   "metadata": {},
   "source": [
    "So you can see our model works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540adbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d777462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf95dac",
   "metadata": {},
   "source": [
    "# Saving the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0ca647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5fe2ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svcfile.obj']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving the best model as an object file(Serialization)\n",
    "joblib.dump(svc,\"svcfile.obj\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc7272",
   "metadata": {},
   "source": [
    "Now my svcfile.obj file is exported where my every python file is save default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfd62d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import \"svcfile.obj\" file again(deserialization) and try to predict with that file again\n",
    "use_svcfile=joblib.load(r\"C:\\Users\\Sourendra\\svcfile.obj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d81bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.array([7.7 ,3.,  6.1, 2.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78c37b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=m.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "961b51ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making prediction with imported svcfile again\n",
    "use_svcfile.predict(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9fe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a20a2679",
   "metadata": {},
   "source": [
    "# Remember we use crossvalidation to give our data a 360 degree view and remove under fitting and overfitting.And you can see in cross_val_score we have to sent x and y value means I put input and output both data means entire data and giving the model and set the cv parameter.I dont have to use train test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d01a1d3",
   "metadata": {},
   "source": [
    "# You might be thinking that crossvalidation type is k-fold so where do I use k-fold?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6e4415",
   "metadata": {},
   "source": [
    "# Listen we use cv parameter right that is the k-fold lets see with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0242ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da549f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         0.86666667 1.         0.86666667]\n",
      "0.9466666666666667\n",
      "0.06531972647421806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#KFold(n_splits=5)\n",
    "kfold=KFold(5)\n",
    "scoreagain=cross_val_score(svc,x,y,cv=kfold)\n",
    "print(scoreagain)\n",
    "print(scoreagain.mean())\n",
    "print(scoreagain.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7025f5",
   "metadata": {},
   "source": [
    "# So you can use k-fold crossvalidation this way but its complex so use direct cv parameter instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd48ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e160363",
   "metadata": {},
   "source": [
    "# Balanced and Unbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ffcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d970bf64",
   "metadata": {},
   "source": [
    "# Balanced dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d120c",
   "metadata": {},
   "source": [
    "Suppose you have a dataset where your y column data is like 0,1,1,1,0,0,1,1,0,1,0,0.So here you can see your y column or output column has six 1 and six 0's that means your dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a4e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c07094",
   "metadata": {},
   "source": [
    "# Unbalanced dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64647b86",
   "metadata": {},
   "source": [
    "Suppose you have a dataset where your y column data is like 0,1,1,1,0,1,1,1,1,1,0,0.Here you can see your y column or output column has eight 1's and four 0's.That means here 1's are in majority and 0's are in minority and this is bad for machine learning.This is the example of Unbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650de66e",
   "metadata": {},
   "source": [
    "So to balanceing the data set we have to use SMOTE technique to balance an unbalance dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278b5bd",
   "metadata": {},
   "source": [
    "SMOTE works like in above example you see there is eight 1's and four 0's in y column so it increase the 0's data to eight also and its adding newly four rows for newly added four 0's output.So now your dataset have 16 rows where in y column there is eight 1's and eight 0's are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22ccb8",
   "metadata": {},
   "source": [
    "In another method we can describe Unbalanced dataset as:-\n",
    "\n",
    "Imagine, you have two categories in your dataset to predict - Category-A and Category-B. When Category-A is higher than Category-B or vice versa, you have a problem of imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50812fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f39f94ad",
   "metadata": {},
   "source": [
    "# SMOTE (Synthetic Minority Over-sampling Technique):-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf6285",
   "metadata": {},
   "source": [
    "SMOTE is an over-sampling method. It creates synthetic samples of the minority class. Hence making the minority class equal to the majority class. SMOTE does this by selecting similar records and altering that record one column at a time by a random amount within the difference to the neighbouring records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63b050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b32676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f7973ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2    3     4      5   6  7\n",
       "6   148  72  35    0  33.6  0.627  50  1\n",
       "1    85  66  29    0  26.6  0.351  31  0\n",
       "8   183  64   0    0  23.3  0.672  32  1\n",
       "1    89  66  23   94  28.1  0.167  21  0\n",
       "0   137  40  35  168  43.1  2.288  33  1\n",
       "..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "10  101  76  48  180  32.9  0.171  63  0\n",
       "2   122  70  27    0  36.8  0.340  27  0\n",
       "5   121  72  23  112  26.2  0.245  30  0\n",
       "1   126  60   0    0  30.1  0.349  47  1\n",
       "1    93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/dataset1/master/pima_indian_diabetes.csv\",na_values=\".\",header=None,names=range(0,8))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49dd20b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2    3     4      5   6\n",
       "6   148  72  35    0  33.6  0.627  50\n",
       "1    85  66  29    0  26.6  0.351  31\n",
       "8   183  64   0    0  23.3  0.672  32\n",
       "1    89  66  23   94  28.1  0.167  21\n",
       "0   137  40  35  168  43.1  2.288  33\n",
       "..  ...  ..  ..  ...   ...    ...  ..\n",
       "10  101  76  48  180  32.9  0.171  63\n",
       "2   122  70  27    0  36.8  0.340  27\n",
       "5   121  72  23  112  26.2  0.245  30\n",
       "1   126  60   0    0  30.1  0.349  47\n",
       "1    93  70  31    0  30.4  0.315  23\n",
       "\n",
       "[768 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=ds.iloc[:,:7]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f44e1421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     1\n",
       "1     0\n",
       "8     1\n",
       "1     0\n",
       "0     1\n",
       "     ..\n",
       "10    0\n",
       "2     0\n",
       "5     0\n",
       "1     1\n",
       "1     0\n",
       "Name: 7, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=ds.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83095295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d42ca",
   "metadata": {},
   "source": [
    "Here you can clearly see this dataset is Unbalanced because value toward 0 is 500 that is majority and value towards 1 is 268 that is minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62d05baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='7', ylabel='count'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79018403",
   "metadata": {},
   "source": [
    "Here you can see graphically that 0's values are in majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b42c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d62e8756",
   "metadata": {},
   "source": [
    "# Applying SMOTE():-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59763aed",
   "metadata": {},
   "source": [
    "To apply SMOTE we have to install a library named imblearn and remember after installing imblearn make that code markdown so that it could not execute again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291c6ff",
   "metadata": {},
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac6b9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3014de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt=SMOTE()\n",
    "\n",
    "newx,newy=smt.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "21689e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1   2   3    4          5         6 \n",
       "0    48  20  0    24.700000  0.140000  22    1\n",
       "138  74  26  144  36.100000  0.557000  50    1\n",
       "136  90  0   0    29.900000  0.210000  50    1\n",
       "137  40  35  168  43.100000  2.288000  33    1\n",
       "     61  0   0    24.200000  0.151000  55    1\n",
       "                                            ..\n",
       "109  62  41  128  35.855350  0.512463  25    1\n",
       "             129  35.800000  0.514000  25    1\n",
       "     64  44  99   34.800000  0.905000  26    1\n",
       "     67  26  0    27.279448  0.175186  37    1\n",
       "199  76  43  0    42.900000  1.394000  22    1\n",
       "Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88fd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "417afffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143afc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f22dd8",
   "metadata": {},
   "source": [
    "Here you can see SMOTE give me new input variable named newx with 1000 rows and corospondindly its gives me newy that is output column where 0's and 1's values are exatcly same both are 500.So it creates 232 rows automatically to balance our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba84754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(newx,newy,test_size=.30,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edbb1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf4eadd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9b5c2418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lm.predict(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390e9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7494497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "source": [
    "print(lm.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09a60118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(round(accuracy_score(pred,y_test),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1467204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eadaf23d",
   "metadata": {},
   "source": [
    "# Now I will load a datset named winequality-red.csv first I will check that this dataset is imbalanced or not,if its imbalanced then I will converts it to Balanced dataset and then I will perform decisionTreeClassifier in it and will fetch accuracy_score,confusion_matrics,classification_report from it.Lets see how can I do that: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8cb75ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9d8f4dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70          0.0             1.9      0.076   \n",
       "1            7.8              0.88          0.0             2.6      0.098   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/dataset1/master/winequality-red.csv\",na_values=\".\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e71e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01caab5a",
   "metadata": {},
   "source": [
    "# Checking for imbalanceness:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3727af6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0434e",
   "metadata": {},
   "source": [
    "You can clearly see majority of data goes for 5 and 6 quality rateing so this dataset is clearly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214c520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "255f0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fe325e",
   "metadata": {},
   "source": [
    "# See imbalanceness graphically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ddb637a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df[\"quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cec40",
   "metadata": {},
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bb3d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "029ce08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt=SMOTE()\n",
    "new_x,new_y=smt.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9c0b082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    681\n",
       "7    681\n",
       "4    681\n",
       "8    681\n",
       "3    681\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfbb0d",
   "metadata": {},
   "source": [
    "Now you can see all quality have the same values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df2ec0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='quality', ylabel='count'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1115b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22203f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(new_x,new_y,test_size=.30,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1485898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is: 1.0\n",
      "Accuracy score is: 0.77\n",
      "[[214   4   6   2   0   0]\n",
      " [  4 160  22   9   4   0]\n",
      " [  2  11 113  44   7   0]\n",
      " [  0  19  50 105  20   1]\n",
      " [  0   2   8  37 162  10]\n",
      " [  0   0   0  10   7 193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.97      0.95      0.96       226\n",
      "           4       0.82      0.80      0.81       199\n",
      "           5       0.57      0.64      0.60       177\n",
      "           6       0.51      0.54      0.52       195\n",
      "           7       0.81      0.74      0.77       219\n",
      "           8       0.95      0.92      0.93       210\n",
      "\n",
      "    accuracy                           0.77      1226\n",
      "   macro avg       0.77      0.76      0.77      1226\n",
      "weighted avg       0.78      0.77      0.78      1226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "dtc=DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(x_train,y_train)\n",
    "print(\"Score is:\",dtc.score(x_train,y_train))\n",
    "\n",
    "preddtc=dtc.predict(x_test)\n",
    "\n",
    "print(\"Accuracy score is:\",round(accuracy_score(preddtc,y_test),2))\n",
    "\n",
    "print(confusion_matrix(preddtc,y_test))\n",
    "\n",
    "print(classification_report(preddtc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486f425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4cb4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bea76df",
   "metadata": {},
   "source": [
    "# Curse of dimensionality reduction:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d95f4e",
   "metadata": {},
   "source": [
    "When your model has too much column like 60,70,200 so model did not learn well so in this situation we have to use a technique named  PCA()- Principle Component Analysis. It will reduce your dataset column to your desired number by merging highly correlated column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e4fb1",
   "metadata": {},
   "source": [
    "Eg-\n",
    "Suppose your dataset has 100 of columns so you can write like :\n",
    "\n",
    "    PCA[n_components=15] \n",
    "\n",
    "    So your 100 columns reduced to 15.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ac36e",
   "metadata": {},
   "source": [
    "# Now I will load a dataset named soner where too much columns is present then I will redused those columns to 10.Lets see how can I do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a246234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/DSData/master/sonar.csv\",na_values=\".\",header=None)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4eec9",
   "metadata": {},
   "source": [
    "Here you can see our dataset has 61 columns and I want to reduce those columns to 10 without dropping any column.Lets see how can I do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1de17c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ds.iloc[:,:-1]\n",
    "y=ds.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a85cf91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 60)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d26dd",
   "metadata": {},
   "source": [
    "# Calling PCA to reduce columns to 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "47812d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=10)\n",
    "#pca=PCA(25)\n",
    "\n",
    "x=pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8c17027e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 10)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42ce79",
   "metadata": {},
   "source": [
    "Here you can see you x input columns reduced to 60 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892d7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "81dd4ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56686d8",
   "metadata": {},
   "source": [
    "Our y column data has string values.Lets apply LabelEncoder to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e241d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21da388f",
   "metadata": {},
   "source": [
    "# Applying LableEncoder to our y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f0163dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ln=LabelEncoder()\n",
    "y=ln.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "88bf0c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8383bb",
   "metadata": {},
   "source": [
    "You can see our y value is changed to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff4cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
